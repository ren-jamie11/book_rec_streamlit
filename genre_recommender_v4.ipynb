{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "861678e7-6ff7-405d-bb73-6288497807c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from static import genres\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45a6902-b273-462b-ac70-031b5a52517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_genre_counts(reviews):\n",
    "    \n",
    "    user_genre_counts = reviews.groupby('user_id')[genres].sum().T  # genres as index\n",
    "    num_reviews_by_user = reviews.groupby('user_id')['title'].count()\n",
    "    user_genre_pct = user_genre_counts.div(num_reviews_by_user, axis = 1)\n",
    "\n",
    "    return user_genre_counts, user_genre_pct\n",
    "\n",
    "genre_labels = pd.read_parquet(\"data/genre_labels.parquet\")\n",
    "all_labeled_reviews = pd.read_parquet(\"data/all_labeled_reviews.parquet\")\n",
    "user_genre_counts, user_genre_pct = get_user_genre_counts(all_labeled_reviews)\n",
    "compact_user_genre_pct = pd.read_parquet(\"data/compact_user_genre_pct.parquet\")\n",
    "main_user_item_matrix = pd.read_parquet(\"data/main_user_item_matrix.parquet\")\n",
    "\n",
    "all_books = pd.read_parquet(\"data/all_books.parquet\")\n",
    "all_books['publish_date'] = all_books['publish_date'].str[:-6]\n",
    "all_books = all_books.drop_duplicates(subset = ['author', 'publish_date', 'rating'])\n",
    "all_books_ratings = all_books[['title', 'rating', 'num_ratings']]\n",
    "books_author_date = all_books[['title', 'author', 'publish_date']]\n",
    "books_author_date = books_author_date.set_index('title')\n",
    "\n",
    "users_data = pd.read_parquet(\"data/users_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b67cae97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476149"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labeled_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8c11251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0031325592105263156"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "476149/(16000*9500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d70bf7ba-7edf-41b0-9f63-c04bd9597ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(count, pct, alpha = 1):\n",
    "    score = count * pct**alpha\n",
    "    return score\n",
    "\n",
    "def min_max_scale(series, max_value = 100):\n",
    "    min_val = series.min()\n",
    "    max_val = series.max()\n",
    "    return ((series - min_val) / (max_val - min_val)) * max_value\n",
    "\n",
    "def normalize_series(series):\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    return (series - mean) / std\n",
    "\n",
    "def get_url_from_user_id(user_id, users_data):\n",
    "    user_row = users_data[users_data.user_id == user_id]\n",
    "    if user_row:\n",
    "        url = user_row['user_url'].values[0]\n",
    "        return url\n",
    "\n",
    "    return \"user url not found...\"\n",
    "\n",
    "\n",
    "def get_top_n_reviewers(ranker, n):\n",
    "    n = min(n, len(ranker))\n",
    "    print(\"n\", n)\n",
    "    top_n = ranker.head(n)\n",
    "    top_n['score_normed'] = top_n['score']/np.sum(top_n['score'])\n",
    "\n",
    "    return top_n\n",
    "\n",
    "\n",
    "def get_expert_user_item_matrix(user_item_matrix, experts):\n",
    "    expert_user_item_matrix =  user_item_matrix[user_item_matrix.index.isin(experts)]\n",
    "    expert_user_item_matrix = expert_user_item_matrix.loc[experts]\n",
    "\n",
    "    return expert_user_item_matrix\n",
    "\n",
    "\n",
    "def get_book_scores_from_experts(user_item_matrix, rating_emphasis):\n",
    "    \"\"\"\n",
    "    Given a user-item rating matrix with users as rows and book titles as columns,\n",
    "    returns a DataFrame with the mean rating and number of ratings per book,\n",
    "    ignoring zero entries.\n",
    "    \"\"\"\n",
    "\n",
    "    masked = user_item_matrix.mask(user_item_matrix == 0)\n",
    "    \n",
    "    avg_ratings = masked.mean(axis=0)\n",
    "    rating_counts = masked.count(axis=0)\n",
    "\n",
    "    book_stats = pd.DataFrame({\n",
    "        \"rating\": avg_ratings,\n",
    "        \"count\": rating_counts\n",
    "    })\n",
    "\n",
    "    book_stats = book_stats.dropna(subset=[\"rating\"])\n",
    "    book_stats['score'] = get_score(book_stats['count'], book_stats['rating'], alpha = rating_emphasis)\n",
    "    book_stats['score'] = min_max_scale(book_stats['score']).round(1)\n",
    "    book_stats = book_stats.sort_values(by=\"score\", ascending=False)\n",
    "    book_stats = book_stats[['score', 'rating', \"count\"]]\n",
    "\n",
    "    return book_stats\n",
    "\n",
    "def format_thousands(series):\n",
    "    \"\"\"\n",
    "    Convert integers to strings formatted in thousands with 'k' suffix.\n",
    "    Examples:\n",
    "        12345 -> '12.3k'\n",
    "        24992 -> '25k'\n",
    "        300   -> '0.3k'\n",
    "    \"\"\"\n",
    "    return series.apply(lambda x: f\"{x/1000:.1f}k\".rstrip('0').rstrip('.'))\n",
    "\n",
    "def filter_book_recs_by_score_or_n(df, n, min_score):\n",
    "    high_score_books = df[df.score >= min_score]\n",
    "    if len(high_score_books) >= n:\n",
    "        return high_score_books.head(n)\n",
    "\n",
    "    return high_score_books\n",
    "\n",
    "\n",
    "def get_bin_labels(arr, width = 0.001):\n",
    "    quantiles = np.arange(0.1, 1.0, width)\n",
    "    quantile_values = np.quantile(arr, quantiles)\n",
    "\n",
    "    bin_indices = np.digitize(arr, quantile_values, right=True)\n",
    "    bin_indices = np.clip(bin_indices, 0, len(quantiles) - 1)\n",
    "    bin_labels = quantiles[bin_indices].round(2)\n",
    "\n",
    "    return bin_labels\n",
    "\n",
    "\n",
    "def enrich_books_with_metadata(recommended_books, book_ratings, metadata):\n",
    "    merged = recommended_books.merge(book_ratings, left_index=True, right_on='title', how='inner')\n",
    "    merged = merged.set_index('title').rename(columns = {'rating_x': 'rating', 'rating_y': 'overall_rating'})\n",
    "    merged_with_book_data = pd.merge(metadata, merged, left_index = True, right_index = True, how = 'right')\n",
    "\n",
    "    return merged_with_book_data\n",
    "\n",
    "\n",
    "def post_process_books(recommended_books, n):\n",
    "    recommended_books = recommended_books[['author', 'publish_date', 'adjusted_score','rating', 'count', 'novelty', 'overall_rating', 'num_ratings']] \n",
    "    recommended_books.columns = ['author', 'published', 'score','rating', 'count', 'novelty', 'goodreads rating', 'ratings']\n",
    "    # recommended_books = recommended_books.drop_duplicates(subset = ['author', 'published', 'goodreads rating'])\n",
    "    recommended_books['score'] = recommended_books['score'].round(1) \n",
    "    recommended_books['rating'] = recommended_books['rating'].round(1) \n",
    "    recommended_books['goodreads rating'] = recommended_books['goodreads rating'].round(1) \n",
    "    recommended_books['ratings'] = format_thousands(recommended_books['ratings'])\n",
    "\n",
    "    return recommended_books.head(n).sort_values(by = 'score', ascending = False)\n",
    "\n",
    "def post_process_neighbors(neighbors, users_data):\n",
    "    user_cols = ['name','genre_similarity', 'read_count']\n",
    "\n",
    "    m_neighbors = pd.merge(neighbors, users_data, left_index = True, right_on = \"user_id\", how = \"left\")\n",
    "    m_neighbors['genre_similarity'] = m_neighbors['genre_similarity'].round(3) \n",
    "    m_neighbors = m_neighbors.set_index('user_id')\n",
    "    m_neighbors = m_neighbors[user_cols]\n",
    "\n",
    "    m_neighbors.columns = ['name', 'genre similarity', 'review samples']\n",
    "    \n",
    "    return m_neighbors\n",
    "\n",
    "def get_recommendation_from_top(ranker, novelty_factor, user_item_matrix,\n",
    "                                users_data, book_ratings, metadata,\n",
    "                                num_reviewers = 100, rating_emphasis = 2, min_similarity = 0.8):\n",
    "    \n",
    "    top_n = get_top_n_reviewers(ranker, num_reviewers)\n",
    "    top_n = top_n[top_n.genre_similarity >= min_similarity]\n",
    "    experts = top_n.index\n",
    "    neighbors = post_process_neighbors(top_n.head(num_reviewers), users_data = users_data)\n",
    "    \n",
    "    # user_item_matrix for top reviewers of this genre\n",
    "    expert_user_item_matrix = get_expert_user_item_matrix(user_item_matrix, experts)\n",
    "    expert_ratings = get_book_scores_from_experts(expert_user_item_matrix, rating_emphasis)\n",
    "\n",
    "    rec_books_with_metadata = enrich_books_with_metadata(expert_ratings, book_ratings, metadata)\n",
    "\n",
    "\n",
    "    rec_books_with_metadata['novelty'] = get_bin_labels(rec_books_with_metadata.num_ratings.values)\n",
    "    rec_books_with_metadata['novelty'] = np.abs(1 - rec_books_with_metadata['novelty'])\n",
    "    rec_books_with_metadata['adjusted_score'] = get_score(count = rec_books_with_metadata['score'],\n",
    "                                                          pct = rec_books_with_metadata['novelty'],\n",
    "                                                          alpha = novelty_factor)\n",
    "    \n",
    "    rec_books_with_metadata['adjusted_score'] = min_max_scale(rec_books_with_metadata['adjusted_score'])\n",
    "    best_books = post_process_books(rec_books_with_metadata, n = 50)\n",
    "\n",
    "    \n",
    "    return best_books, neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "915141e4-ec8e-4509-919c-f6c7f8c01329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_reviews_with_genre(all_reviews, genre_labels):\n",
    "    all_labeled_reviews = all_reviews.merge(\n",
    "        genre_labels, \n",
    "        on='title', \n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    all_labeled_reviews = all_labeled_reviews.drop_duplicates(subset=['title', 'user_id', 'rating'])\n",
    "    return all_labeled_reviews\n",
    "\n",
    "def get_user_genre_counts_and_pcts(user_reviews, genre_labels):\n",
    "    this_user_reviews_labeled = label_reviews_with_genre(user_reviews, genre_labels)\n",
    "    this_user_genre_counts, this_user_genre_pct = get_user_genre_counts(this_user_reviews_labeled)\n",
    "\n",
    "    return this_user_genre_counts, this_user_genre_pct\n",
    "\n",
    "def get_user_similarities_ranker_by_genre(this_user_genre_pct, user_genre_counts, other_users_genre_pct, alpha, min_similarity):\n",
    "    # construct matrix\n",
    "    M = other_users_genre_pct.values\n",
    "    v = this_user_genre_pct.values\n",
    "    similarities = cosine_similarity(M.T, v.T).ravel()\n",
    "    other_users = other_users_genre_pct.T.index\n",
    "    similarity_ranker = pd.DataFrame({'other_users': other_users, 'genre_similarity': similarities})\n",
    "    \n",
    "    # Formatting the similarity table\n",
    "    similarity_ranker = similarity_ranker.set_index(\"other_users\")\n",
    "    similarity_ranker['read_count'] = user_genre_counts.sum(axis = 0)\n",
    "    similarity_ranker = similarity_ranker[similarity_ranker.genre_similarity >= min_similarity]\n",
    "    similarity_ranker['score'] = get_score(similarity_ranker['read_count'], similarity_ranker['genre_similarity'], alpha = alpha)\n",
    "    similarity_ranker = similarity_ranker.sort_values(by = 'score', ascending = False) \n",
    "    \n",
    "    return similarity_ranker\n",
    "\n",
    "\n",
    "\"\"\" USE THIS FOR CUSTOME GENRE PCT\"\"\"\n",
    "def recommend_books_by_custom_genre_pct(custom_user_genre_pct, novelty_factor,\n",
    "                                        user_genre_counts, other_users_genre_pct,\n",
    "                                        user_item_matrix, users_data, book_ratings,\n",
    "                                        metadata, user_reviews = None):\n",
    "\n",
    "    genre_similarity_ranker = get_user_similarities_ranker_by_genre(custom_user_genre_pct, user_genre_counts, other_users_genre_pct,\n",
    "                                                                    alpha = 250, min_similarity = 0.8)\n",
    "    \n",
    "    recommended_books, neighbors = get_recommendation_from_top(genre_similarity_ranker, novelty_factor, user_item_matrix,\n",
    "                                                               users_data, book_ratings, metadata)\n",
    "    \n",
    "    if len(user_reviews) > 0:\n",
    "        recommended_books = recommended_books[~recommended_books.index.isin(user_reviews.title.values)]\n",
    "    \n",
    "    return recommended_books, neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91c0620d-fe4e-432a-8f7d-637e3d45ccb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n 100\n",
      "Elapsed, 0.24 seconds\n"
     ]
    }
   ],
   "source": [
    "user_reviews = pd.read_parquet(\"data/default_reviews.parquet\")\n",
    "this_user_genre_counts, this_user_genre_pct = get_user_genre_counts_and_pcts(user_reviews, genre_labels = genre_labels)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "recommended_books, neighbors = recommend_books_by_custom_genre_pct(this_user_genre_pct, novelty_factor = .1, user_reviews = user_reviews,\n",
    "                                                                   user_genre_counts = user_genre_counts, other_users_genre_pct = compact_user_genre_pct,\n",
    "                                                                   user_item_matrix = main_user_item_matrix, users_data = users_data, \n",
    "                                                                   book_ratings = all_books_ratings, metadata = books_author_date)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Elapsed, {(end - start):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbc18bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>155041466-jamie-ren</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Art</th>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biography</th>\n",
       "      <td>0.128205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business</th>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chick Lit</th>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Children's</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Christian</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classics</th>\n",
       "      <td>0.256410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comics</th>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contemporary</th>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cookbooks</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ebooks</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>0.179487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction</th>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gay and Lesbian</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graphic Novels</th>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Historical Fiction</th>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History</th>\n",
       "      <td>0.128205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humor and Comedy</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manga</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Memoir</th>\n",
       "      <td>0.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonfiction</th>\n",
       "      <td>0.487179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paranormal</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philosophy</th>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poetry</th>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Psychology</th>\n",
       "      <td>0.358974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Religion</th>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science</th>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science Fiction</th>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self Help</th>\n",
       "      <td>0.358974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suspense</th>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spirituality</th>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports</th>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Travel</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young Adult</th>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id             155041466-jamie-ren\n",
       "Art                            0.025641\n",
       "Biography                      0.128205\n",
       "Business                       0.230769\n",
       "Chick Lit                      0.025641\n",
       "Children's                     0.000000\n",
       "Christian                      0.000000\n",
       "Classics                       0.256410\n",
       "Comics                         0.025641\n",
       "Contemporary                   0.076923\n",
       "Cookbooks                      0.000000\n",
       "Crime                          0.051282\n",
       "Ebooks                         0.000000\n",
       "Fantasy                        0.179487\n",
       "Fiction                        0.512821\n",
       "Gay and Lesbian                0.000000\n",
       "Graphic Novels                 0.051282\n",
       "Historical Fiction             0.076923\n",
       "History                        0.128205\n",
       "Horror                         0.025641\n",
       "Humor and Comedy               0.000000\n",
       "Manga                          0.000000\n",
       "Memoir                         0.102564\n",
       "Music                          0.000000\n",
       "Mystery                        0.025641\n",
       "Nonfiction                     0.487179\n",
       "Paranormal                     0.000000\n",
       "Philosophy                     0.384615\n",
       "Poetry                         0.025641\n",
       "Psychology                     0.358974\n",
       "Religion                       0.025641\n",
       "Romance                        0.076923\n",
       "Science                        0.025641\n",
       "Science Fiction                0.153846\n",
       "Self Help                      0.358974\n",
       "Suspense                       0.025641\n",
       "Spirituality                   0.051282\n",
       "Sports                         0.025641\n",
       "Thriller                       0.025641\n",
       "Travel                         0.000000\n",
       "Young Adult                    0.051282"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_user_genre_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ca36aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f73609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133e579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eee1e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c45f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fedfbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c054bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357abdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c01869d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32053c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff2d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8a3f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc16dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53061954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
